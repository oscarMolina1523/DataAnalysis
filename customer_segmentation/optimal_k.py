from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

"""
    Esta funci√≥n busca el n√∫mero √≥ptimo de clusters (K) para segmentar clientes
    usando dos m√©todos: el 'codo' (inertia) y el 'silhouette'.
    
    Par√°metros:
    - rfm_scaled: DataFrame con los datos de clientes escalados (RFM normalizado).
    - max_k: n√∫mero m√°ximo de clusters a probar (default = 10).
"""
def find_optimal_k(rfm_scaled, max_k=10):
    # Guardamos resultados de cada K
    inertia = []  # Almacenar√° qu√© tan compactos son los grupos
    silhouette_scores = [] # Almacenar√° qu√© tan bien separados est√°n los grupos

    # Probaremos distintos valores de K (desde 2 hasta max_k)
    # No probamos con K=1 porque silhouette no se puede calcular con 1 grupo.
    K = range(2, max_k+1)

    for k in K:
        # 1. Creamos el modelo KMeans con k clusters
        km = KMeans(n_clusters=k, random_state=42)
        # 2. Entrenamos el modelo y obtenemos las etiquetas (a qu√© cluster pertenece cada cliente)
        labels = km.fit_predict(rfm_scaled)
        # 3. Guardamos la "inercia":
        #    mide la suma de distancias de los clientes a sus centros de cluster.
        #    Cuanto m√°s baja ‚Üí m√°s compactos los grupos.
        inertia.append(km.inertia_)
        # 4. Calculamos el "silhouette score":
        #    mide qu√© tan bien separados y definidos est√°n los clusters.
        #    Valor cercano a 1 ‚Üí clusters bien separados.
        silhouette_scores.append(silhouette_score(rfm_scaled, labels))

    # üìä Elbow method visualization
    # Se busca el punto donde la mejora en la inercia deja de ser significativa
    plt.plot(K, inertia, "bx-")
    plt.xlabel("K")
    plt.ylabel("Inertia")
    plt.title("M√©todo del codo")
    plt.show()

    # üìä Silhouette visualization
    # Se busca el K con mayor silhouette score ‚Üí clusters bien definidos y separados
    plt.plot(K, silhouette_scores, "rx-")
    plt.xlabel("K")
    plt.ylabel("Silhouette Score")
    plt.title("Silhouette Method")
    plt.show()


# üìä 1. M√©todo del Codo (Inertia)

# En el gr√°fico azul, la inertia baja a medida que aumentas K (cantidad de clusters).

# Lo que buscas es el ‚Äúcodo‚Äù, es decir, el punto donde la curva deja de bajar fuerte y empieza a aplanarse.

# En tu gr√°fico:

# De K=2 a K=4 la ca√≠da es muy fuerte.

# De K=5 en adelante la curva ya baja poquito.

# üîé Entonces, el codo est√° m√°s o menos en K=4 o K=5.
# Eso significa que 4 o 5 clusters son un buen n√∫mero para segmentar.

# üìä 2. M√©todo del Silhouette

# Este mide qu√© tan ‚Äúcompactos y separados‚Äù est√°n los clusters (0 a 1, m√°s alto = mejor).

# En tu gr√°fico rojo:

# El valor m√°s alto est√° en K=3 (~0.35).

# Luego va bajando y los clusters se vuelven menos definidos.

# üîé Eso significa que el clustering m√°s claro y separado lo logras con K=3.

# üß© C√≥mo juntarlos

# El codo sugiere 4 o 5 clusters (bueno para balancear tama√±o).

# El silhouette sugiere 3 clusters (mejor separaci√≥n, m√°s calidad).

# No existe una respuesta absoluta:

# Si prefieres calidad de clusters bien separados, usa 3 clusters.

# Si prefieres m√°s detalle en los grupos (aunque con algo m√°s de mezcla), usa 4 o 5 clusters.